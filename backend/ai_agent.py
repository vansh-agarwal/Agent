"""
AI Agent for Personal Task Automation
LLM-based intelligent task planning and autonomous decision-making
Supports Google Gemini API
"""

import os
import json
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from models import Task, CalendarEvent, Priority, IntentType, UserIntent
from nlp_engine import NLPEngine

# Try to import Gemini
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("Warning: google-generativeai not installed. Using NLP-only mode.")


class AIAgent:
    """LLM-powered autonomous agent for task automation"""
    
    def __init__(self, api_key: Optional[str] = None):
        """Initialize AI agent with Gemini or fallback to NLP-only"""
        self.api_key = api_key or os.getenv('GEMINI_API_KEY') or os.getenv('OPENAI_API_KEY')
        self.model = None
        self.nlp_engine = NLPEngine()
        
        # Try to initialize Gemini
        if GEMINI_AVAILABLE and self.api_key:
            try:
                genai.configure(api_key=self.api_key)
                self.model = genai.GenerativeModel('gemini-1.5-flash')
                print("тЬУ Gemini AI initialized successfully")
            except Exception as e:
                print(f"Warning: Could not initialize Gemini: {e}")
                self.model = None
        
        # Agent personality and system prompt - ENHANCED FOR GENERAL INTELLIGENCE
        self.system_prompt = """You are ARIA, an intelligent AI assistant with broad knowledge and task automation capabilities.
You can help users with:
1. Task management (creating tasks, todos)
2. Calendar/scheduling (events, meetings, appointments with times)
3. Email composition and sending
4. GENERAL KNOWLEDGE questions on ANY topic (science, history, math, coding, health, etc.)
5. ML-powered predictions (career advice, productivity analysis, customer insights)
6. Complex problem solving and explanations

## CATEGORIZATION RULES:

### RULE 1: ANYTHING WITH A SPECIFIC TIME тЖТ create_event (CALENDAR)
If the user mentions a time ("at 6:30 pm", "tomorrow at 3pm"), use create_event

### RULE 2: TASK WITHOUT TIME тЖТ create_task
Use create_task when user says "task", "todo", "remind me" without specific time

### RULE 3: GENERAL QUESTIONS тЖТ general_response
For questions like:
- "What is quantum computing?"
- "How does photosynthesis work?"
- "Explain machine learning"
- "What's the capital of France?"
- "Help me with this code"
- "Give me career advice"
Use action: "general_response" and provide a helpful answer

### RULE 4: ML PREDICTION REQUESTS тЖТ ml_prediction
For requests like:
- "Predict my career income"
- "Analyze employee productivity"
- "What customer segment am I?"
Use action: "ml_prediction" with appropriate type

## RESPONSE FORMAT:
{
  "action": "create_task" | "create_event" | "send_email" | "query_tasks" | "query_events" | "general_response" | "ml_prediction",
  "parameters": {...},
  "response": "Your helpful response"
}

For general_response:
- Provide accurate, helpful information
- Be conversational and engaging
- Use examples and analogies when helpful

RESPOND WITH VALID JSON ONLY. NO MARKDOWN. NO EXPLANATION OUTSIDE JSON."""

    
    def process_user_input(self, user_message: str, context: Optional[Dict] = None) -> Dict:
        """
        Process user input and determine appropriate action
        
        Args:
            user_message: Natural language input from user
            context: Optional context (existing tasks, events, etc.)
            
        Returns:
            Dict with action type and parameters
        """
        # First, use NLP engine for quick local intent extraction
        intent = self.nlp_engine.extract_intent(user_message)
        
        # If we have Gemini configured, use it for enhanced understanding
        if self.model and context:
            try:
                enhanced_result = self._gemini_enhanced_processing(user_message, intent, context)
                return enhanced_result
            except Exception as e:
                print(f"Gemini processing error: {e}")
                # Fallback to NLP-only
                return self._create_action_from_intent(intent)
        else:
            # Fallback to NLP-only processing
            return self._create_action_from_intent(intent)
    
    def _gemini_enhanced_processing(self, user_message: str, base_intent: UserIntent, context: Dict) -> Dict:
        """Use Gemini for enhanced understanding and intelligent decision-making"""
        
        # Prepare context for LLM
        context_str = json.dumps({
            'existing_tasks': context.get('tasks', [])[:10],  # Limit context size
            'upcoming_events': context.get('events', [])[:5],
            'current_time': datetime.now().isoformat()
        }, indent=2, default=str)
        
        # Create prompt for Gemini
        prompt = f"""{self.system_prompt}

User request: "{user_message}"

Current context:
{context_str}

Respond with a JSON object only. No markdown, no explanation, just the JSON."""
        
        try:
            response = self.model.generate_content(prompt)
            result_text = response.text.strip()
            
            # Extract JSON from response (handle markdown code blocks)
            if '```json' in result_text:
                result_text = result_text.split('```json')[1].split('```')[0].strip()
            elif '```' in result_text:
                result_text = result_text.split('```')[1].split('```')[0].strip()
            
            result = json.loads(result_text)
            
            # Merge with base intent for fallback
            result['base_intent'] = base_intent.to_dict()
            
            return result
            
        except Exception as e:
            print(f"Gemini processing error: {e}")
            # Fallback to NLP-only
            return self._create_action_from_intent(base_intent)
    
    def _create_action_from_intent(self, intent: UserIntent) -> Dict:
        """Create action dictionary from NLP intent (fallback when no LLM)"""
        return {
            'action': intent.intent_type.value,
            'parameters': intent.entities,
            'priority': intent.entities.get('priority', 'MEDIUM'),
            'reasoning': 'Based on natural language processing',
            'conflicts': [],
            'suggestions': [],
            'confidence': intent.confidence
        }
    
    def prioritize_tasks(self, tasks: List[Dict]) -> List[Dict]:
        """Intelligently prioritize tasks using AI"""
        
        if not self.model or not tasks:
            # Fallback: simple rule-based prioritization
            return self._rule_based_prioritization(tasks)
        
        # Use Gemini for intelligent prioritization
        tasks_summary = [
            {
                'id': t['id'],
                'title': t['title'],
                'deadline': t.get('deadline'),
                'priority': t.get('priority'),
                'estimated_duration': t.get('estimated_duration')
            }
            for t in tasks[:20]  # Limit to avoid token limits
        ]
        
        prompt = f"""Analyze these tasks and suggest optimal prioritization order:

Tasks:
{json.dumps(tasks_summary, indent=2, default=str)}

Current time: {datetime.now().isoformat()}

Provide a JSON object with: {{"prioritized_ids": [id1, id2, id3, ...], "reasoning": "brief explanation"}}
Respond with JSON only."""
        
        try:
            response = self.model.generate_content(prompt)
            result_text = response.text.strip()
            
            if '```json' in result_text:
                result_text = result_text.split('```json')[1].split('```')[0].strip()
            elif '```' in result_text:
                result_text = result_text.split('```')[1].split('```')[0].strip()
            
            result = json.loads(result_text)
            prioritized_ids = result.get('prioritized_ids', [])
            
            # Reorder tasks based on LLM suggestions
            id_to_task = {t['id']: t for t in tasks}
            prioritized = []
            for task_id in prioritized_ids:
                if task_id in id_to_task:
                    prioritized.append(id_to_task[task_id])
            
            # Add any remaining tasks not included in prioritization
            for task in tasks:
                if task not in prioritized:
                    prioritized.append(task)
            
            return prioritized
            
        except Exception as e:
            print(f"Prioritization error: {e}")
            return self._rule_based_prioritization(tasks)
    
    def _rule_based_prioritization(self, tasks: List[Dict]) -> List[Dict]:
        """Simple rule-based prioritization fallback"""
        priority_order = {'URGENT': 0, 'HIGH': 1, 'MEDIUM': 2, 'LOW': 3}
        
        def sort_key(task):
            priority_score = priority_order.get(task.get('priority', 'MEDIUM'), 2)
            deadline = task.get('deadline')
            if deadline:
                try:
                    deadline_dt = datetime.fromisoformat(deadline.replace('Z', '+00:00'))
                    hours_until = (deadline_dt - datetime.now()).total_seconds() / 3600
                    time_score = max(0, min(100, hours_until))
                except:
                    time_score = 100
            else:
                time_score = 100
            return (priority_score, time_score)
        
        return sorted(tasks, key=sort_key)
    
    def suggest_schedule(self, events: List[Dict], new_event_duration: int) -> Dict:
        """Suggest optimal time slot for new event"""
        
        if not self.model:
            # Fallback: suggest next available hour
            now = datetime.now()
            suggested = now.replace(hour=now.hour + 1, minute=0, second=0, microsecond=0)
            return {
                'suggested_time': suggested.isoformat(),
                'reasoning': 'Next available hour slot'
            }
        
        # Use Gemini for intelligent scheduling
        events_summary = [
            {
                'title': e.get('title'),
                'start': e.get('start_time'),
                'end': e.get('end_time')
            }
            for e in events[:10]
        ]
        
        prompt = f"""Analyze these existing events and suggest the best time for a {new_event_duration}-minute meeting:

Existing events:
{json.dumps(events_summary, indent=2, default=str)}

Current time: {datetime.now().isoformat()}

Suggest an optimal time slot. Respond with JSON: {{"suggested_time": "ISO datetime", "reasoning": "brief explanation"}}"""
        
        try:
            response = self.model.generate_content(prompt)
            result_text = response.text.strip()
            
            if '```json' in result_text:
                result_text = result_text.split('```json')[1].split('```')[0].strip()
            elif '```' in result_text:
                result_text = result_text.split('```')[1].split('```')[0].strip()
            
            return json.loads(result_text)
        except Exception as e:
            print(f"Schedule suggestion error: {e}")
            now = datetime.now()
            suggested = now.replace(hour=now.hour + 1, minute=0, second=0, microsecond=0)
            return {
                'suggested_time': suggested.isoformat(),
                'reasoning': 'Next available hour slot'
            }
    
    def draft_email(self, subject: str, context: str, tone: str = 'professional') -> str:
        """Draft an email using AI"""
        
        if not self.model:
            return f"Subject: {subject}\n\n{context}"
        
        prompt = f"""Draft a {tone} email with the following:

Subject: {subject}
Context/Key Points: {context}

Write a complete, well-structured email that is concise and clear. Respond with just the email body."""
        
        try:
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            print(f"Email drafting error: {e}")
            return f"Subject: {subject}\n\n{context}"
    
    def chat_response(self, user_message: str, conversation_history: List[Dict] = None, action_result: Dict = None, language: str = 'english') -> str:
        """Generate conversational response to user in selected language"""
        
        # Language-specific responses for actions
        action_responses = {
            'english': {
                'task_created': "тЬЕ Done! I've added that to your task list. Is there anything else you'd like me to help with?",
                'event_created': "ЁЯУЕ Perfect! I've scheduled that event on your calendar. You're all set! ЁЯОЙ",
                'email_sent': "ЁЯУз Your email has been sent! Let me know if you need to send another.",
                'tasks_retrieved': "ЁЯУЛ Here are your tasks! You've got {} task(s). Anything you'd like me to add or change?",
                'events_retrieved': "ЁЯУЕ You have {} upcoming event(s). Want me to schedule something new?",
                'no_tasks': "ЁЯУЛ Your task list is empty! That's great if you're all done, or I can help add something new.",
                'no_events': "ЁЯУЕ No upcoming events on your calendar. Want me to schedule one?"
            },
            'hindi': {
                'task_created': "тЬЕ рд╣реЛ рдЧрдпрд╛! рдореИрдВрдиреЗ рдЗрд╕реЗ рдЖрдкрдХреА рдЯрд╛рд╕реНрдХ рд▓рд┐рд╕реНрдЯ рдореЗрдВ рдЬреЛрдбрд╝ рджрд┐рдпрд╛ рд╣реИред рдХреНрдпрд╛ рдХреБрдЫ рдФрд░ рдорджрдж рдЪрд╛рд╣рд┐рдП?",
                'event_created': "ЁЯУЕ рдмрдврд╝рд┐рдпрд╛! рдореИрдВрдиреЗ рдпрд╣ рдЗрд╡реЗрдВрдЯ рдЖрдкрдХреЗ рдХреИрд▓реЗрдВрдбрд░ рдореЗрдВ рд╢реЗрдбреНрдпреВрд▓ рдХрд░ рджрд┐рдпрд╛ рд╣реИ! ЁЯОЙ",
                'email_sent': "ЁЯУз рдЖрдкрдХрд╛ рдИрдореЗрд▓ рднреЗрдЬ рджрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ! рдмрддрд╛рдЗрдП рдХреНрдпрд╛ рдХреБрдЫ рдФрд░ рднреЗрдЬрдирд╛ рд╣реИ?",
                'tasks_retrieved': "ЁЯУЛ рдЖрдкрдХреЗ {} рдЯрд╛рд╕реНрдХ рд╣реИрдВред рдХреБрдЫ рдЬреЛрдбрд╝рдирд╛ рдпрд╛ рдмрджрд▓рдирд╛ рд╣реИ?",
                'events_retrieved': "ЁЯУЕ рдЖрдкрдХреЗ {} рдЖрдЧрд╛рдореА рдЗрд╡реЗрдВрдЯ рд╣реИрдВред рдХреБрдЫ рдирдпрд╛ рд╢реЗрдбреНрдпреВрд▓ рдХрд░рдирд╛ рд╣реИ?",
                'no_tasks': "ЁЯУЛ рдЖрдкрдХреА рдЯрд╛рд╕реНрдХ рд▓рд┐рд╕реНрдЯ рдЦрд╛рд▓реА рд╣реИ! рдХреБрдЫ рдирдпрд╛ рдЬреЛрдбрд╝реВрдВ?",
                'no_events': "ЁЯУЕ рдХреЛрдИ рдЖрдЧрд╛рдореА рдЗрд╡реЗрдВрдЯ рдирд╣реАрдВ рд╣реИред рдХреБрдЫ рд╢реЗрдбреНрдпреВрд▓ рдХрд░реВрдВ?"
            },
            'tamil': {
                'task_created': "тЬЕ роорпБроЯро┐роирпНродродрпБ! роЙроЩрпНроХро│рпН рокрогро┐рокрпНрокроЯрпНроЯро┐ропро▓ро┐ро▓рпН роЪрпЗро░рпНродрпНродрпБро╡ро┐роЯрпНроЯрпЗройрпН. ро╡рпЗро▒рпБ роПродро╛ро╡родрпБ роЙродро╡ро┐ ро╡рпЗрогрпНроЯрпБрооро╛?",
                'event_created': "ЁЯУЕ роЕро░рпБроорпИ! роЙроЩрпНроХро│рпН роиро╛роЯрпНроХро╛роЯрпНроЯро┐ропро┐ро▓рпН роиро┐роХро┤рпНро╡рпИ родро┐роЯрпНроЯрооро┐роЯрпНроЯрпБро╡ро┐роЯрпНроЯрпЗройрпН! ЁЯОЙ",
                'email_sent': "ЁЯУз роЙроЩрпНроХро│рпН рооро┐ройрпНройроЮрпНроЪро▓рпН роЕройрпБрокрпНрокрокрпНрокроЯрпНроЯродрпБ! ро╡рпЗро▒рпБ роПродро╛ро╡родрпБ роЕройрпБрокрпНрок ро╡рпЗрогрпНроЯрпБрооро╛?",
                'tasks_retrieved': "ЁЯУЛ роЙроЩрпНроХро│рпБроХрпНроХрпБ {} рокрогро┐роХро│рпН роЙро│рпНро│ройред роПродро╛ро╡родрпБ роЪрпЗро░рпНроХрпНроХ ро╡рпЗрогрпНроЯрпБрооро╛?",
                'events_retrieved': "ЁЯУЕ роЙроЩрпНроХро│рпБроХрпНроХрпБ {} ро╡ро░ро╡ро┐ро░рпБроХрпНроХрпБроорпН роиро┐роХро┤рпНро╡рпБроХро│рпН роЙро│рпНро│ройред рокрпБродро┐ропродрпИ родро┐роЯрпНроЯрооро┐роЯро▓ро╛рооро╛?",
                'no_tasks': "ЁЯУЛ роЙроЩрпНроХро│рпН рокрогро┐рокрпНрокроЯрпНроЯро┐ропро▓рпН роХро╛ро▓ро┐ропро╛роХ роЙро│рпНро│родрпБ! рокрпБродро┐родро╛роХ роЪрпЗро░рпНроХрпНроХро▓ро╛рооро╛?",
                'no_events': "ЁЯУЕ ро╡ро░ро╡ро┐ро░рпБроХрпНроХрпБроорпН роиро┐роХро┤рпНро╡рпБроХро│рпН роЗро▓рпНро▓рпИ. роПродро╛ро╡родрпБ родро┐роЯрпНроЯрооро┐роЯро▓ро╛рооро╛?"
            }
        }
        
        responses = action_responses.get(language, action_responses['english'])
        
        # If we have action result, generate a response based on that
        if action_result and action_result.get('success'):
            action_type = action_result.get('type', '')
            if action_type == 'task_created':
                return responses['task_created']
            elif action_type == 'event_created':
                return responses['event_created']
            elif action_type == 'email_sent':
                return responses['email_sent']
            elif action_type == 'tasks_retrieved':
                tasks = action_result.get('tasks', [])
                if tasks:
                    return responses['tasks_retrieved'].format(len(tasks))
                return responses['no_tasks']
            elif action_type == 'events_retrieved':
                events = action_result.get('events', [])
                if events:
                    return responses['events_retrieved'].format(len(events))
                return responses['no_events']
        
        # Try Gemini for natural conversation in selected language
        if self.model:
            lang_instruction = {
                'english': 'Respond in English.',
                'hindi': 'Respond in Hindi (рд╣рд┐рдВрджреА рдореЗрдВ рдЬрд╡рд╛рдм рджреЗрдВ). Use Devanagari script.',
                'tamil': 'Respond in Tamil (родрооро┐ро┤ро┐ро▓рпН рокродро┐ро▓ро│ро┐роХрпНроХро╡рпБроорпН). Use Tamil script.'
            }
            
            prompt = f"""You are ARIA, a highly intelligent AI assistant with BROAD KNOWLEDGE on any topic.

## YOUR CAPABILITIES:
1. **General Knowledge**: Answer questions about science, history, geography, math, technology, culture, etc.
2. **Technical Help**: Explain coding, algorithms, software, engineering concepts
3. **Life Advice**: Career guidance, personal development, health tips, productivity advice
4. **Problem Solving**: Help analyze problems, provide solutions, compare options
5. **Creative Tasks**: Write stories, poems, summaries, explanations
6. **Task Management**: Schedule events, create tasks, send emails

## PERSONALITY:
- Warm, friendly, and genuinely helpful ЁЯШК
- Uses occasional emojis to express emotions
- Explains complex topics in simple, understandable ways
- Provides accurate, well-reasoned answers
- Admits when uncertain and suggests alternatives

## IMPORTANT RULES:
- For factual questions, provide accurate, detailed answers
- For complex topics, break down explanations step-by-step
- For career/life questions, give thoughtful, practical advice
- Always be helpful - never say "I can only help with tasks/calendar"

{lang_instruction.get(language, lang_instruction['english'])}

User said: {user_message}

Provide a helpful, informative response. Be conversational but thorough. If it's a complex question, explain well. If it's a simple chat, be friendly and brief."""
            
            try:
                response = self.model.generate_content(prompt)
                return response.text.strip()
            except Exception as e:
                print(f"Chat error: {e}")
        
        # Rule-based fallback responses by language
        fallback = {
            'english': {
                'greet': "Hello! ЁЯСЛ Great to see you! How can I make your day easier?",
                'task': "I'll create that task for you right away! тЬЕ",
                'event': "Let me add that to your calendar! ЁЯУЕ",
                'email': "I'll help you send that email! ЁЯУз",
                'help': "I'm here to help! I can:\nтАв Create tasks: 'Remind me to...'\nтАв Schedule events: 'Schedule meeting at...'\nтАв Send emails: 'Email someone about...'\nтАв Chat: 'How's my day looking?'",
                'default': "Got it! Let me help you with that. ЁЯдЭ"
            },
            'hindi': {
                'greet': "рдирдорд╕реНрддреЗ! ЁЯСЛ рдЖрдкрд╕реЗ рдорд┐рд▓рдХрд░ рдЦреБрд╢реА рд╣реБрдИ! рдЖрдЬ рдореИрдВ рдХреИрд╕реЗ рдорджрдж рдХрд░ рд╕рдХрддрд╛ рд╣реВрдВ?",
                'task': "рдореИрдВ рдЕрднреА рд╡рд╣ рдЯрд╛рд╕реНрдХ рдмрдирд╛ рджреЗрддрд╛ рд╣реВрдВ! тЬЕ",
                'event': "рдореИрдВ рдЗрд╕реЗ рдЖрдкрдХреЗ рдХреИрд▓реЗрдВрдбрд░ рдореЗрдВ рдЬреЛрдбрд╝ рджреЗрддрд╛ рд╣реВрдВ! ЁЯУЕ",
                'email': "рдореИрдВ рд╡рд╣ рдИрдореЗрд▓ рднреЗрдЬрдиреЗ рдореЗрдВ рдорджрдж рдХрд░рддрд╛ рд╣реВрдВ! ЁЯУз",
                'help': "рдореИрдВ рдпрд╣рд╛рдВ рдорджрдж рдХреЗ рд▓рд┐рдП рд╣реВрдВ!\nтАв рдЯрд╛рд╕реНрдХ: 'рдореБрдЭреЗ рдпрд╛рдж рджрд┐рд▓рд╛рдУ...'\nтАв рдЗрд╡реЗрдВрдЯ: 'рдореАрдЯрд┐рдВрдЧ рд╢реЗрдбреНрдпреВрд▓ рдХрд░реЛ...'\nтАв рдИрдореЗрд▓: 'рдХрд┐рд╕реА рдХреЛ рдИрдореЗрд▓ рдХрд░реЛ...'",
                'default': "рд╕рдордЭ рдЧрдпрд╛! рдореИрдВ рдЗрд╕рдореЗрдВ рдЖрдкрдХреА рдорджрдж рдХрд░рддрд╛ рд╣реВрдВред ЁЯдЭ"
            },
            'tamil': {
                'greet': "ро╡рогроХрпНроХроорпН! ЁЯСЛ роЙроЩрпНроХро│рпИрокрпН рокро╛ро░рпНродрпНродродро┐ро▓рпН роороХро┐ро┤рпНроЪрпНроЪро┐! роиро╛ройрпН роОрокрпНрокроЯро┐ роЙродро╡ роорпБроЯро┐ропрпБроорпН?",
                'task': "роЙроЯройрпЗ роЕроирпНрод рокрогро┐ропрпИ роЙро░рпБро╡ро╛роХрпНроХрпБроХро┐ро▒рпЗройрпН! тЬЕ",
                'event': "роЙроЩрпНроХро│рпН роиро╛роЯрпНроХро╛роЯрпНроЯро┐ропро┐ро▓рпН роЪрпЗро░рпНроХрпНроХро┐ро▒рпЗройрпН! ЁЯУЕ",
                'email': "роЕроирпНрод рооро┐ройрпНройроЮрпНроЪро▓рпИ роЕройрпБрокрпНрок роЙродро╡рпБроХро┐ро▒рпЗройрпН! ЁЯУз",
                'help': "роиро╛ройрпН роЙродро╡ роЗроЩрпНроХрпЗ роЗро░рпБроХрпНроХро┐ро▒рпЗройрпН!\nтАв рокрогро┐роХро│рпН: 'роОройроХрпНроХрпБ роиро┐ройрпИро╡рпВроЯрпНроЯрпБ...'\nтАв роиро┐роХро┤рпНро╡рпБроХро│рпН: 'роЪроирпНродро┐рокрпНрокрпИ родро┐роЯрпНроЯрооро┐роЯрпБ...'\nтАв рооро┐ройрпНройроЮрпНроЪро▓рпН: 'ропро╛ро░рпБроХрпНроХро╛ро╡родрпБ рооро┐ройрпНройроЮрпНроЪро▓рпН роЕройрпБрокрпНрокрпБ...'",
                'default': "рокрпБро░ро┐роирпНродродрпБ! роЗродро┐ро▓рпН роЙроЩрпНроХро│рпБроХрпНроХрпБ роЙродро╡рпБроХро┐ро▒рпЗройрпНред ЁЯдЭ"
            }
        }
        
        lang_fallback = fallback.get(language, fallback['english'])
        msg_lower = user_message.lower()
        
        if any(word in msg_lower for word in ['task', 'todo', 'remind', 'рдЯрд╛рд╕реНрдХ', 'рдпрд╛рдж', 'рокрогро┐']):
            return lang_fallback['task']
        elif any(word in msg_lower for word in ['meeting', 'schedule', 'calendar', 'event', 'рдореАрдЯрд┐рдВрдЧ', 'рдХреИрд▓реЗрдВрдбрд░', 'роЪроирпНродро┐рокрпНрокрпБ', 'роиро╛роЯрпНроХро╛роЯрпНроЯро┐']):
            return lang_fallback['event']
        elif any(word in msg_lower for word in ['email', 'send', 'mail', 'рдИрдореЗрд▓', 'рднреЗрдЬ', 'рооро┐ройрпНройроЮрпНроЪро▓рпН']):
            return lang_fallback['email']
        elif any(word in msg_lower for word in ['hi', 'hello', 'hey', 'рдирдорд╕реНрддреЗ', 'рд╣рд╛рдп', 'ро╡рогроХрпНроХроорпН']):
            return lang_fallback['greet']
        elif any(word in msg_lower for word in ['help', 'what can', 'рдорджрдж', 'роЙродро╡ро┐']):
            return lang_fallback['help']
        else:
            return lang_fallback['default']

